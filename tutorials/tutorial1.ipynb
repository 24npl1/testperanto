{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testperanto tutorial 1: our first fake words\n",
    "-------------------------------------------------\n",
    "\n",
    "Let's begin with the following piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 10/10 [00:00<00:00, 4279.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banana\n",
      "apple\n",
      "banana\n",
      "banana\n",
      "apple\n",
      "banana\n",
      "apple\n",
      "apple\n",
      "apple\n",
      "apple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from testperanto.config import init_grammar_macro, generate_sentences\n",
    "\n",
    "config = {\"grammar\": [\n",
    "            {\"rule\": \"START -> NN\"},\n",
    "            {\"rule\": \"NN -> (@verbatim apple)\"},\n",
    "            {\"rule\": \"NN -> (@verbatim banana)\"}\n",
    "          ]}\n",
    "grammar = init_grammar_macro(config)\n",
    "for sent in generate_sentences(grammar, start_state='START', num_to_generate=10):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines (and generates some sentences from) a simple context-free grammar (CFG). Nonterminals should always start with a capital letter, whereas terminals should be enclosed by parentheses. Syntactically, these terminals are the only departure from a typical CFG. Terminals should be expressed in the format:\n",
    "\n",
    "    (@vbox vinput)\n",
    "\n",
    "where ```vbox``` is the name of the \"voicebox\" we want to use, and ```vinput``` is the input to the voicebox. In ```testperanto```, the role of the voicebox is to translate generic words into specific words, for instance, mapping something like ```noun.52``` to the word apple. The most straightforward voicebox is the ```verbatim``` voicebox, which simply renders words verbatim. \n",
    "\n",
    "Applicable rules are chosen randomly, with probability proportional to their weights. By default, each rule has a equivalent weight of ```1.0```, so you should have seen a roughly equal proportion of apples and bananas. But we can specify different rule weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 10/10 [00:00<00:00, 4151.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banana\n",
      "apple\n",
      "apple\n",
      "banana\n",
      "banana\n",
      "apple\n",
      "banana\n",
      "banana\n",
      "banana\n",
      "banana\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"grammar\": [\n",
    "            {\"rule\": \"START -> NN\"},\n",
    "            {\"rule\": \"NN -> (@verbatim apple)\", \"base_weight\": 0.2},\n",
    "            {\"rule\": \"NN -> (@verbatim banana)\", \"base_weight\": 0.8}\n",
    "          ]}\n",
    "grammar = init_grammar_macro(config)\n",
    "for sent in generate_sentences(grammar, start_state='START', num_to_generate=10):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should generate more bananas than apples. Rather than choose words ourselves, we can get ```testperanto``` to come up with words for us. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 5/5 [00:00<00:00, 3878.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dagudun\n",
      "dagudun\n",
      "dagudun\n",
      "dagudun\n",
      "dagudun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"grammar\": [\n",
    "            {\"rule\": \"START -> NN\"},\n",
    "            {\"rule\": \"NN -> (@nn (STEM noun.52) (COUNT sng))\"}\n",
    "          ]}\n",
    "grammar = init_grammar_macro(config)\n",
    "for sent in generate_sentences(grammar, start_state='START', num_to_generate=5):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default voicebox theme is ```\"english\"```, and thus uses English morphology. For instance, if we ask for a plural noun, it will add an ```\"s\"```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 5/5 [00:00<00:00, 3059.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flaglojals\n",
      "flaglojals\n",
      "flaglojals\n",
      "flaglojals\n",
      "flaglojals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"grammar\": [\n",
    "            {\"rule\": \"START -> NN\"},\n",
    "            {\"rule\": \"NN -> (@nn (STEM noun.34) (COUNT plu))\"}\n",
    "          ]}\n",
    "grammar = init_grammar_macro(config)\n",
    "for sent in generate_sentences(grammar, start_state='START', num_to_generate=5):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```\"english\"``` theme ends verbs with the suffix ```-ize```, and can perform some simple tenses and conjugations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 10/10 [00:00<00:00, 2394.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "present: meekanizes\n",
      "present: meekanizes\n",
      "present: meekanizes\n",
      "perfect: meekanized\n",
      "present: meekanizes\n",
      "present: meekanizes\n",
      "perfect: meekanized\n",
      "perfect: meekanized\n",
      "perfect: meekanized\n",
      "present: meekanizes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"grammar\": [\n",
    "            {\"rule\": \"START -> VB\"},\n",
    "            {\"rule\": \"VB -> (@verbatim present:) (@vb (STEM verb.281) (COUNT sng) (PERSON 3) (TENSE present))\"},\n",
    "            {\"rule\": \"VB -> (@verbatim perfect:) (@vb (STEM verb.281) (COUNT sng) (PERSON 3) (TENSE perfect))\"}\n",
    "          ]}\n",
    "grammar = init_grammar_macro(config)\n",
    "for sent in generate_sentences(grammar, start_state='START', num_to_generate=10):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of an alternative theme, ```testperanto``` also provides the stub of a Romanized ```\"japanese\"``` theme. Note that we don't need to recreate the grammar, we just render the generic words with a different voicebox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of testperanto.wordgenerators failed: Traceback (most recent call last):\n",
      "  File \"/Users/markhopkins/opt/anaconda3/envs/spred2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/markhopkins/opt/anaconda3/envs/spred2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/markhopkins/opt/anaconda3/envs/spred2/lib/python3.8/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/markhopkins/opt/anaconda3/envs/spred2/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/markhopkins/Documents/projects/testperanto/testperanto/wordgenerators.py\", line 221, in <module>\n",
      "    SyllabaryWordGenerator.from_json(\"foo.json\"))\n",
      "  File \"/Users/markhopkins/Documents/projects/testperanto/testperanto/wordgenerators.py\", line 211, in from_json\n",
      "    with open(filename) as reader:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'foo.json'\n",
      "]\n",
      "100%|██████████████████████████████████████████████████| 10/10 [00:00<00:00, 3724.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "present: reratuhemasu\n",
      "perfect: reratuhemashita\n",
      "perfect: reratuhemashita\n",
      "present: reratuhemasu\n",
      "perfect: reratuhemashita\n",
      "present: reratuhemasu\n",
      "perfect: reratuhemashita\n",
      "present: reratuhemasu\n",
      "present: reratuhemasu\n",
      "present: reratuhemasu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import testperanto.wordgenerators\n",
    "import testperanto.voicebox\n",
    "for sent in generate_sentences(grammar, start_state='START', num_to_generate=10, vbox_theme=\"japanese\"):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
