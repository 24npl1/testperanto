{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testperanto tutorial 4: our first fake phrases\n",
    "---------------------------------------------------\n",
    "\n",
    "So far we've been focusing on generating individual words in a \"language-like\" manner. In this tutorial, we'll extend this to short adjective-noun phrases. We'll start by generating both nouns and adjectives from independent Pitman-Yor distributions, having chosen parameters that match the statistics of real nouns and adjectives from the English Europarl corpus (using the methodology of Tutorial 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 5/5 [00:00<00:00, 2555.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['kafunish cugap',\n",
       " 'fucugunish baglokeefran',\n",
       " 'glocish froglux',\n",
       " 'frudoflogish cufrap',\n",
       " 'gujuglukish haluc']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"grammar\": [\n",
    "            {\"rule\": \"START -> ADJ NN\"},\n",
    "            {\"rule\": \"NN -> (@nn (STEM noun.$z1) (COUNT sng))\", \"zdists\": [\"nn\"]},\n",
    "            {\"rule\": \"ADJ -> (@adj (STEM adj.$z1))\", \"zdists\": [\"adj\"]}\n",
    "          ],\n",
    "          \"distributions\": [\n",
    "            {\"name\": \"nn\", \"type\": \"pyor\", \"discount\": 0.4, \"strength\": 500.0},\n",
    "            {\"name\": \"adj\", \"type\": \"pyor\", \"discount\": 0.4, \"strength\": 500.0}\n",
    "          ]}\n",
    "from testperanto.config import init_wrig, generate_sentences\n",
    "generate_sentences(init_wrig(config), start_state='START', num_to_generate=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how \"natural\" these generated adjective-noun pairs are. We'll use the same approach that we previously used in Tutorial 3, and compare the singleton proportion of our generated phrases with the singleton proportion of actual adjective-noun phrases extracted from the Europarl corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [00:34<00:00, 2921.39it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/europarl.en.amod.100k.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m independent \u001b[38;5;241m=\u001b[39m generate_sentences(init_wrig(config), start_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTART\u001b[39m\u001b[38;5;124m'\u001b[39m, num_to_generate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m)\n\u001b[1;32m      6\u001b[0m europarl_en \u001b[38;5;241m=\u001b[39m stream_lines(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/europarl.en.amod.100k.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mplot_singleton_proportion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43meuroparl_en\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindependent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meuroparl_en\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindependent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/research/tpo/code/testperanto/analysis.py:155\u001b[0m, in \u001b[0;36mplot_singleton_proportion\u001b[0;34m(corpora, corpus_labels)\u001b[0m\n\u001b[1;32m    153\u001b[0m axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msemilogx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m y_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingleton proportion\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 155\u001b[0m \u001b[43mplot_statistic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpora\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpowers_of_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m               \u001b[49m\u001b[43mcorpus_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_label\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/research/tpo/code/testperanto/analysis.py:111\u001b[0m, in \u001b[0;36mplot_statistic\u001b[0;34m(stat_fn, corpora, x_values, axes, corpus_labels, x_label, y_label)\u001b[0m\n\u001b[1;32m    109\u001b[0m     corpus_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorpus\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(corpora))]\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, token_stream \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(corpora)):\n\u001b[0;32m--> 111\u001b[0m     x_vals, y_vals \u001b[38;5;241m=\u001b[39m \u001b[43mstat_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [[corpus_labels[i], x,y] \u001b[38;5;28;01mfor\u001b[39;00m [x,y] \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x_vals, y_vals)]\n\u001b[1;32m    113\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorpus\u001b[39m\u001b[38;5;124m'\u001b[39m, x_label, y_label])\n",
      "File \u001b[0;32m~/Documents/projects/research/tpo/code/testperanto/analysis.py:70\u001b[0m, in \u001b[0;36msingleton_proportion\u001b[0;34m(token_stream, x_values)\u001b[0m\n\u001b[1;32m     68\u001b[0m x_points \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     69\u001b[0m y_points \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m token_stream:\n\u001b[1;32m     71\u001b[0m     token_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m token_counts:\n",
      "File \u001b[0;32m~/Documents/projects/research/tpo/code/testperanto/util.py:118\u001b[0m, in \u001b[0;36mstream_lines\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream_lines\u001b[39m(filename):\n\u001b[1;32m    105\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Streams the lines from an input file.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m        Stream of lines from the input file.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m reader:\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[1;32m    120\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/europarl.en.amod.100k.txt'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from testperanto.analysis import plot_singleton_proportion\n",
    "from testperanto.util import stream_lines\n",
    "\n",
    "independent = generate_sentences(init_wrig(config), start_state='START', num_to_generate=100000)\n",
    "europarl_en = stream_lines('./europarl.en.amod.100k.txt')\n",
    "plot_singleton_proportion([europarl_en, independent], ['europarl_en', 'independent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like generating the adjectives and nouns independently doesn't look language-like at all!\n",
    "The \"real English\" Europarl curve shows a steady log-linear degradation in singleton proportion, while the \"generated English\" curve does not.\n",
    "\n",
    "The problem is the fact that we're generating adjectives and nouns from independent distributions. Just because the adjective `red` is more likely than the adjective `yellow`, that shouldn't mean that the bigram `red banana` is more likely than the bigram `yellow banana`. \n",
    "\n",
    "It would be nice if we could generate the adjective from a distribution that depends on the choice of noun. Luckily we can use our y- and z-variables to do so! In addition to our independent noun and adjective distributions, we introduce a **indexed distribution** `adj.$y1` that generates distributions that are dependent on the choice of noun `$y1`. For instance, `adj.1` will be the adjective distribution we use for `noun.1`, `adj.2` will be the adjective distribution we use for `noun.2`. To ensure that each distribution still uses the same set of adjectives, each distribution `adj.$y1` is a Pitman-Yor process whose base distribution is `adj` (this happens implicitly -- `testperanto` assumes that the base distribution of a distribution named `a.b.c` is `a.b` and the base distribution of a distribution named `a.b.` is `a`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"grammar\": [\n",
    "            {\"rule\": \"START -> NP.$z1\", \"zdists\": [\"nn\"]},\n",
    "            {\"rule\": \"NP.$y1 -> ADJ.$z1 NN.$y1\", \"zdists\": [\"adj.$y1\"]},\n",
    "            {\"rule\": \"NN.$y1 -> (@nn (STEM noun.$y1) (COUNT sng))\"},\n",
    "            {\"rule\": \"ADJ.$y1 -> (@adj (STEM adj.$y1))\"}\n",
    "          ],\n",
    "          \"distributions\": [\n",
    "            {\"name\": \"nn\", \"type\": \"pyor\", \"discount\": 0.4, \"strength\": 500.0},\n",
    "            {\"name\": \"adj\", \"type\": \"pyor\", \"discount\": 0.4, \"strength\": 500.0},\n",
    "            {\"name\": \"adj.$y1\", \"type\": \"pyor\", \"discount\": 0.6, \"strength\": 2.0}\n",
    "          ]}\n",
    "generate_sentences(init_wrig(config), start_state='START', num_to_generate=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that these newly dependent adjective-noun pairs do a much better job of emulating the singleton proportion statistics of natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent = generate_sentences(init_wrig(config), start_state='START', num_to_generate=100000)\n",
    "europarl_en = stream_lines('../data/europarl.en.amod.100k.txt')\n",
    "plot_singleton_proportion([europarl_en, independent, dependent], ['europarl_en', 'independent', 'dependent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
